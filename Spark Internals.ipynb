{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Query Optimization](pics/Query%20Optimization.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache\n",
    "\n",
    "- **df.cache()** -> Will persist the df in the cluster memory  \n",
    "*By doing so, you will be using Spark memory for storage which affects its efficiency*\n",
    "- **df.unpersist()** -> Will unpersist the df from the cluster memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from JDBCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "      .jdbc(\n",
    "        url=\"jdbc:driver://ip/db_name\",\n",
    "        table=\"db_name.table_name\",\n",
    "        column=\"col_1\", #Name of the column that will be used for partitioning\n",
    "        lowerBound=1, #Min value of col_1 to decide partition stride\n",
    "        upperBound=1000000, #Max value of col_1 to decide partition stride\n",
    "        numPartitions=8, #Number of partitions/connections\n",
    "        properties={\"user\" : \"user_name\",\n",
    "                    \"password\" : \"user_password\"}\n",
    "      )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions\n",
    "Partitions are created that are equal to the number of CPU cores in the machine.  \n",
    "Data in a partition exists on a single node in the cluster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Core/Slot** -> Means a thread available for parallel execution. It can also be called **Slot**  \n",
    "*Generally, the number of slots is decided while setting the cluster but in case it is unknown, the way to check is:*  \n",
    "*sc.defaultParallelism*  \n",
    "*spark.sparkContext.defaultParallelism*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Partitions** -> Small piece of a dataset.  \n",
    "*To find the number of partitions of a RDD, you can use:*  \n",
    "*df.rdd.getNumPartitions()*\n",
    "\n",
    "Partitions should be equal or a multiple of the number of cores.  \n",
    "The recommended size for each partition is 200MB.  \n",
    "When using less than that per partition, lower the number to 1 partition per core.  \n",
    "When using more than that, increase the number of partitions by a multiple of the number of cores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repartition a DataFrame:\n",
    "- **coalesce()** -> Returns new df with exactly N partitions when N < current n# of partitions  \n",
    "*Narrow transformation, performs better*  \n",
    "*No Shuffling*  \n",
    "*Not able to increase n# of partitions*\n",
    "  \n",
    "- **repartition()** -> Returns new df with exactly N partitions  \n",
    "*Wide transformation*  \n",
    "*Evenly balanced partition sizes*  \n",
    "*Requires shuffling all data*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle Partitions:\n",
    "To set the number of shuffle partitions:  \n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", value)  \n",
    "\n",
    "To check the number of shuffle partitions:  \n",
    "print(spark.conf.get(\"spark.sql.shuffle.partitions\")  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Query Execution (Spark 3):\n",
    "Able to coalesce shuffle partitions at runtime. The following command controls whether AQE is on/off:  \n",
    "spark.conf.get(\"spark.sql.adaptive.enabled\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
